{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/n1/1kkk0h452_3c_bkk319bsdhw0000gn/T/tmpvf5zi077\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c1fd43a90>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/var/folders/n1/1kkk0h452_3c_bkk319bsdhw0000gn/T/tmpvf5zi077'}\n",
      "WARNING:tensorflow:tf.variable_op_scope(values, name, default_name) is deprecated, use tf.variable_scope(name, default_name, values)\n",
      "INFO:tensorflow:Created variable linear/bias_weight:0, with device=\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/n1/1kkk0h452_3c_bkk319bsdhw0000gn/T/tmpvf5zi077/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /var/folders/n1/1kkk0h452_3c_bkk319bsdhw0000gn/T/tmpvf5zi077/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.08671142.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVM(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinarySvmHead object at 0x1c1fd43978>, 'feature_columns': (_RealValuedColumn(column_name='x', dimension=128, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': <tensorflow.contrib.linear_optimizer.python.sdca_optimizer.SDCAOptimizer object at 0x1c1fd438d0>, 'weight_column_name': None, 'update_weights_hook': <tensorflow.contrib.learn.python.learn.estimators.linear._SdcaUpdateWeightsHook object at 0x1c1fd43940>})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[x[0], x[3]] for x in iris.data])\n",
    "Y = np.array([1 if y==0 else 0 for y in iris.target], dtype=np.int32)\n",
    "example_id = np.array(['%d' % i for i in range(len(Y))])\n",
    "\n",
    "x_column_name = 'x'\n",
    "example_id_column_name = 'example_id'\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={x_column_name: X, example_id_column_name: example_id},\n",
    "    y=Y,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "svm = tf.contrib.learn.SVM(\n",
    "    example_id_column=example_id_column_name,\n",
    "    feature_columns=(tf.contrib.layers.real_valued_column(\n",
    "        column_name=x_column_name, dimension=128),),\n",
    "    l2_regularization=0.1)\n",
    "\n",
    "svm.fit(input_fn=train_input_fn, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize placeholders\n",
    "x_data = tf.placeholder(shape=[None, 8], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "prediction_grid = tf.placeholder(shape=[None, 8], dtype=tf.float32)\n",
    "\n",
    "# Gaussian (RBF) kernel\n",
    "gamma = tf.constant(-10.0)\n",
    "sq_dists = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\n",
    "my_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9f5c1c203bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Compute SVM Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfirst_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb_vec_cross\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "b = tf.Variable(tf.random_normal(shape=[1, batch_size]))\n",
    "\n",
    "# Compute SVM Model\n",
    "first_term = tf.reduce_sum(b)\n",
    "b_vec_cross = tf.matmul(tf.transpose(b), b)\n",
    "y_target_cross = tf.matmul(y_target, tf.transpose(y_target))\n",
    "second_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(b_vec_cross, y_target_cross)))\n",
    "loss = tf.negative(tf.subtract(first_term, second_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #75\n",
      "Loss = -124.293335\n",
      "Step #150\n",
      "Loss = -236.79324\n",
      "Step #225\n",
      "Loss = -349.29318\n",
      "Step #300\n",
      "Loss = -461.7933\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dimension = 2\n",
    "N = 150\n",
    "grid_step = 1  # default value was 0.02\n",
    "\n",
    "x_dummy = np.random.random((N, dimension))\n",
    "y_dummy = np.random.choice(['fear', 'abc'], (N, 1))\n",
    "matrix = np.hstack((x_dummy, y_dummy))\n",
    "\n",
    "## SVM con Tensorflow\n",
    "sess = tf.Session()\n",
    "x_vals = np.array([[x[0], x[3]] for x in iris.data])\n",
    "y_vals = np.array([1 if y==0 else 0 for y in iris.target], dtype=np.int32)\n",
    "# x_vals = np.array([x[0:dimension] for x in matrix])\n",
    "# y_vals = np.array([1 if y[dimension] == 'fear' else -1 for y in matrix])\n",
    "\n",
    "# Split the train data and testing data\n",
    "train_indices = np.random.choice(len(x_vals), int(round(len(x_vals)*0.8)), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "\n",
    "class1_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\n",
    "class1_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == 1]\n",
    "class2_x = [x[0] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\n",
    "class2_y = [x[1] for i, x in enumerate(x_vals_train) if y_vals_train[i] == -1]\n",
    "\n",
    "# Declare batch size\n",
    "batch_size = N\n",
    "\n",
    "# Initialize placeholders\n",
    "x_data = tf.placeholder(shape=[None, dimension], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "prediction_grid = tf.placeholder(shape=[None, dimension], dtype=tf.float32)\n",
    "\n",
    "# Create variables for svm\n",
    "b = tf.Variable(tf.random_normal(shape=[1, batch_size]))\n",
    "\n",
    "# Gaussian (RBF) kernel\n",
    "gamma = tf.constant(-10.0)\n",
    "sq_dists = tf.multiply(2., tf.matmul(x_data, tf.transpose(x_data)))\n",
    "my_kernel = tf.exp(tf.multiply(gamma, tf.abs(sq_dists)))\n",
    "\n",
    "# Compute SVM Model\n",
    "first_term = tf.reduce_sum(b)\n",
    "b_vec_cross = tf.matmul(tf.transpose(b), b)\n",
    "y_target_cross = tf.matmul(y_target, tf.transpose(y_target))\n",
    "second_term = tf.reduce_sum(tf.multiply(my_kernel, tf.multiply(b_vec_cross, y_target_cross)))\n",
    "loss = tf.negative(tf.subtract(first_term, second_term))\n",
    "\n",
    "# Gaussian (RBF) prediction kernel\n",
    "rA = tf.reshape(tf.reduce_sum(tf.square(x_data), 1), [-1, 1])\n",
    "rB = tf.reshape(tf.reduce_sum(tf.square(prediction_grid), 1), [-1, 1])\n",
    "pred_sq_dist = tf.add(tf.subtract(rA, tf.multiply(2., tf.matmul(x_data, tf.transpose(prediction_grid)))), tf.transpose(rB))\n",
    "pred_kernel = tf.exp(tf.multiply(gamma, tf.abs(pred_sq_dist)))\n",
    "\n",
    "prediction_output = tf.matmul(tf.multiply(tf.transpose(y_target), b), pred_kernel)\n",
    "prediction = tf.sign(prediction_output - tf.reduce_mean(prediction_output))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(prediction), tf.squeeze(y_target)), tf.float32))\n",
    "\n",
    "# Declare optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Training loop\n",
    "loss_vec = []\n",
    "batch_accuracy = []\n",
    "for i in range(300):\n",
    "    rand_index = np.random.choice(len(x_vals), size=batch_size)\n",
    "    rand_x = x_vals[rand_index]\n",
    "    rand_y = np.transpose([y_vals[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    loss_vec.append(temp_loss)\n",
    "\n",
    "    acc_temp = sess.run(accuracy, feed_dict={x_data: rand_x,\n",
    "                                             y_target: rand_y,\n",
    "                                             prediction_grid: rand_x})\n",
    "    batch_accuracy.append(acc_temp)\n",
    "\n",
    "    if (i + 1) % 75 == 0:\n",
    "        print('Step #' + str(i + 1))\n",
    "        print('Loss = ' + str(temp_loss))\n",
    "\n",
    "# # Create a mesh to plot points in\n",
    "# x_vals = x_vals.astype(np.float)\n",
    "# # this code is used as a generalization to work with all dimensions\n",
    "# x_ranges = np.vstack((x_vals.min(axis=0) - 1, x_vals.max(axis=0) + 1)).T\n",
    "# aranges = [np.arange(x_range[0], x_range[1], grid_step) for x_range in x_ranges]\n",
    "# print('grid size:', np.power(len(aranges[0]), dimension))\n",
    "# meshes = np.meshgrid(*aranges)\n",
    "# grid_points = np.vstack(tuple([mesh.ravel() for mesh in meshes])).T\n",
    "# print('grid size:', grid_points.shape)\n",
    "# [grid_predictions] = sess.run(prediction, feed_dict={x_data: x_vals,\n",
    "#                                                      y_target: np.transpose([y_vals]),\n",
    "#                                                      prediction_grid: grid_points})\n",
    "\n",
    "# # Plot points and grid\n",
    "# # this is the old mesh generation code that is kept since it is used in the plots\n",
    "# x_min, x_max = x_vals[:, 0].min() - 1, x_vals[:, 0].max() + 1\n",
    "# y_min, y_max = x_vals[:, 1].min() - 1, x_vals[:, 1].max() + 1\n",
    "# xx_arange = np.arange(x_min, x_max, grid_step)\n",
    "# yy_arange = np.arange(y_min, y_max, grid_step)\n",
    "# xx, yy = np.meshgrid(xx_arange,yy_arange)\n",
    "# size = np.power(len(xx), 2)\n",
    "# grid_predictions = grid_predictions[0:size].reshape(xx.shape)\n",
    "\n",
    "# plt.contourf(xx, yy, grid_predictions, cmap=plt.cm.Paired, alpha=0.8)\n",
    "# plt.plot(class1_x, class1_y, 'ro', label='I. setosa')\n",
    "# plt.plot(class2_x, class2_y, 'kx', label='Non setosa')\n",
    "# plt.title('Gaussian SVM Results on Iris Data')\n",
    "# plt.xlabel('Petal Length')\n",
    "# plt.ylabel('Sepal Width')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylim([-0.5, 3.0])\n",
    "# plt.xlim([3.5, 8.5])\n",
    "# plt.show()\n",
    "\n",
    "# # Plot batch accuracy\n",
    "# plt.plot(batch_accuracy, 'k-', label='Accuracy')\n",
    "# plt.title('Batch Accuracy')\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot loss over time\n",
    "# plt.plot(loss_vec, 'k-')\n",
    "# plt.title('Loss per Generation')\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
